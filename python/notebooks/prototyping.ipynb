{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b45567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded parquet file with 36718 rows using pandas\n",
      "\n",
      "Loaded 10916756 characters\n",
      "First 500 chars:\n",
      " = Valkyria Chronicles III = \n",
      "\n",
      " Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs p\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_wikitext2_from_parquet(parquet_path=\"../../train-00000-of-00001.parquet\", text_column=\"text\"):\n",
    "    parquet_file = Path(parquet_path)\n",
    "    \n",
    "    if not parquet_file.exists():\n",
    "        raise FileNotFoundError(f\"Parquet file not found: {parquet_path}\")\n",
    "    \n",
    "        \n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    print(f\"Loaded parquet file with {len(df)} rows using pandas\")\n",
    "    \n",
    "    if text_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{text_column}' not found. Available columns: {df.columns.tolist()}\")\n",
    "    \n",
    "\n",
    "    texts = df[text_column].dropna().astype(str)\n",
    "    texts = texts[texts.str.strip() != '']  \n",
    "    text = '\\n'.join(texts)\n",
    "    \n",
    "    return text\n",
    "    \n",
    "text = load_wikitext2_from_parquet()\n",
    "print(f\"\\nLoaded {len(text)} characters\")\n",
    "print(f\"First 500 chars:\\n{text[:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00bc0a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10916756"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac9aed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_SIZE = 0.1\n",
    "subtext = text[:int(len(text) * SUBSET_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad2b33a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' =',\n",
       " ' Valkyria',\n",
       " ' Chronicles',\n",
       " ' III',\n",
       " ' =',\n",
       " ' \\n\\n',\n",
       " ' Senjō',\n",
       " ' no',\n",
       " ' Valkyria',\n",
       " ' ',\n",
       " '3']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule = re.compile(r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}++|\\p{N}{1,3}+| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*+|\\s++$|\\s*[\\r\\n]|\\s+(?!\\S)|\\s\"\"\")\n",
    "pretokens = re.findall(rule, subtext)\n",
    "\n",
    "pretokens[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b98319f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " \"'t\",\n",
       " ' this',\n",
       " ' is',\n",
       " ' a',\n",
       " ' ',\n",
       " '123',\n",
       " '455',\n",
       " '4',\n",
       " ' test',\n",
       " \"'ll\",\n",
       " ' of',\n",
       " ' a',\n",
       " ' tokenizer',\n",
       " ' made',\n",
       " ' by',\n",
       " ' ME',\n",
       " \"'VE\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = \"hello't this is a 1234554 test'll of a tokenizer made by ME'VE\"\n",
    "re.findall(rule, tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2510fb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[32, 61],\n",
       " [32, 86, 97, 108, 107, 121, 114, 105, 97],\n",
       " [32, 67, 104, 114, 111, 110, 105, 99, 108, 101, 115],\n",
       " [32, 73, 73, 73],\n",
       " [32, 61],\n",
       " [32, 10, 10],\n",
       " [32, 83, 101, 110, 106, 333],\n",
       " [32, 110, 111],\n",
       " [32, 86, 97, 108, 107, 121, 114, 105, 97],\n",
       " [32],\n",
       " [51]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byteStream = [[ord(char) for char in token] for token in pretokens]\n",
    "byteStream[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7550cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStats(bts, stats):\n",
    "    for pair in zip(bts, bts[1:]):\n",
    "        stats[pair] = stats.get(pair, 0) + 1\n",
    "    return stats\n",
    "\n",
    "def merge(byteStream, pair, idx):\n",
    "    i = 0\n",
    "    newStream = []\n",
    "    while i < len(byteStream):\n",
    "        if i < (len(byteStream)-1) and byteStream[i] == pair[0] and byteStream[i+1] == pair[1]:\n",
    "            newStream.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            newStream.append(byteStream[i])\n",
    "            i += 1\n",
    "    return newStream\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69da5e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[32, 61],\n",
       " [32, 86, 97, 108, 107, 121, 114, 105, 97],\n",
       " [32, 67, 104, 114, 111, 110, 105, 99, 108, 101, 115],\n",
       " [32, 73, 73, 73],\n",
       " [32, 61],\n",
       " [32, 10, 10],\n",
       " [32, 83, 101, 110, 106, 197, 141],\n",
       " [32, 110, 111],\n",
       " [32, 86, 97, 108, 107, 121, 114, 105, 97],\n",
       " [32],\n",
       " [51]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [list(ch.encode('utf-8')) for ch in pretokens]\n",
    "ids[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f49f531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2744/2744 [13:30<00:00,  3.39it/s]\n"
     ]
    }
   ],
   "source": [
    "def bpe(pretokens, vocab_size=3000):\n",
    "    num_merges = vocab_size - 256\n",
    "    vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "    merges = {}\n",
    "    for i in tqdm(range(num_merges)):\n",
    "        stats = {}\n",
    "        for chunk in pretokens:\n",
    "            getStats(chunk, stats)\n",
    "        maxPair = max(stats, key=stats.get)\n",
    "        idx = 256 + i\n",
    "        merges[maxPair] = idx\n",
    "        pretokens = [merge(chunk, maxPair, idx) for chunk in pretokens]\n",
    "        vocab[idx] = vocab[maxPair[0]] + vocab[maxPair[1]]\n",
    "            \n",
    "    return vocab, merges\n",
    "\n",
    "vocab, merges = bpe(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa1883a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: b'\\x00',\n",
       " 1: b'\\x01',\n",
       " 2: b'\\x02',\n",
       " 3: b'\\x03',\n",
       " 4: b'\\x04',\n",
       " 5: b'\\x05',\n",
       " 6: b'\\x06',\n",
       " 7: b'\\x07',\n",
       " 8: b'\\x08',\n",
       " 9: b'\\t',\n",
       " 10: b'\\n',\n",
       " 11: b'\\x0b',\n",
       " 12: b'\\x0c',\n",
       " 13: b'\\r',\n",
       " 14: b'\\x0e',\n",
       " 15: b'\\x0f',\n",
       " 16: b'\\x10',\n",
       " 17: b'\\x11',\n",
       " 18: b'\\x12',\n",
       " 19: b'\\x13',\n",
       " 20: b'\\x14',\n",
       " 21: b'\\x15',\n",
       " 22: b'\\x16',\n",
       " 23: b'\\x17',\n",
       " 24: b'\\x18',\n",
       " 25: b'\\x19',\n",
       " 26: b'\\x1a',\n",
       " 27: b'\\x1b',\n",
       " 28: b'\\x1c',\n",
       " 29: b'\\x1d',\n",
       " 30: b'\\x1e',\n",
       " 31: b'\\x1f',\n",
       " 32: b' ',\n",
       " 33: b'!',\n",
       " 34: b'\"',\n",
       " 35: b'#',\n",
       " 36: b'$',\n",
       " 37: b'%',\n",
       " 38: b'&',\n",
       " 39: b\"'\",\n",
       " 40: b'(',\n",
       " 41: b')',\n",
       " 42: b'*',\n",
       " 43: b'+',\n",
       " 44: b',',\n",
       " 45: b'-',\n",
       " 46: b'.',\n",
       " 47: b'/',\n",
       " 48: b'0',\n",
       " 49: b'1',\n",
       " 50: b'2',\n",
       " 51: b'3',\n",
       " 52: b'4',\n",
       " 53: b'5',\n",
       " 54: b'6',\n",
       " 55: b'7',\n",
       " 56: b'8',\n",
       " 57: b'9',\n",
       " 58: b':',\n",
       " 59: b';',\n",
       " 60: b'<',\n",
       " 61: b'=',\n",
       " 62: b'>',\n",
       " 63: b'?',\n",
       " 64: b'@',\n",
       " 65: b'A',\n",
       " 66: b'B',\n",
       " 67: b'C',\n",
       " 68: b'D',\n",
       " 69: b'E',\n",
       " 70: b'F',\n",
       " 71: b'G',\n",
       " 72: b'H',\n",
       " 73: b'I',\n",
       " 74: b'J',\n",
       " 75: b'K',\n",
       " 76: b'L',\n",
       " 77: b'M',\n",
       " 78: b'N',\n",
       " 79: b'O',\n",
       " 80: b'P',\n",
       " 81: b'Q',\n",
       " 82: b'R',\n",
       " 83: b'S',\n",
       " 84: b'T',\n",
       " 85: b'U',\n",
       " 86: b'V',\n",
       " 87: b'W',\n",
       " 88: b'X',\n",
       " 89: b'Y',\n",
       " 90: b'Z',\n",
       " 91: b'[',\n",
       " 92: b'\\\\',\n",
       " 93: b']',\n",
       " 94: b'^',\n",
       " 95: b'_',\n",
       " 96: b'`',\n",
       " 97: b'a',\n",
       " 98: b'b',\n",
       " 99: b'c',\n",
       " 100: b'd',\n",
       " 101: b'e',\n",
       " 102: b'f',\n",
       " 103: b'g',\n",
       " 104: b'h',\n",
       " 105: b'i',\n",
       " 106: b'j',\n",
       " 107: b'k',\n",
       " 108: b'l',\n",
       " 109: b'm',\n",
       " 110: b'n',\n",
       " 111: b'o',\n",
       " 112: b'p',\n",
       " 113: b'q',\n",
       " 114: b'r',\n",
       " 115: b's',\n",
       " 116: b't',\n",
       " 117: b'u',\n",
       " 118: b'v',\n",
       " 119: b'w',\n",
       " 120: b'x',\n",
       " 121: b'y',\n",
       " 122: b'z',\n",
       " 123: b'{',\n",
       " 124: b'|',\n",
       " 125: b'}',\n",
       " 126: b'~',\n",
       " 127: b'\\x7f',\n",
       " 128: b'\\x80',\n",
       " 129: b'\\x81',\n",
       " 130: b'\\x82',\n",
       " 131: b'\\x83',\n",
       " 132: b'\\x84',\n",
       " 133: b'\\x85',\n",
       " 134: b'\\x86',\n",
       " 135: b'\\x87',\n",
       " 136: b'\\x88',\n",
       " 137: b'\\x89',\n",
       " 138: b'\\x8a',\n",
       " 139: b'\\x8b',\n",
       " 140: b'\\x8c',\n",
       " 141: b'\\x8d',\n",
       " 142: b'\\x8e',\n",
       " 143: b'\\x8f',\n",
       " 144: b'\\x90',\n",
       " 145: b'\\x91',\n",
       " 146: b'\\x92',\n",
       " 147: b'\\x93',\n",
       " 148: b'\\x94',\n",
       " 149: b'\\x95',\n",
       " 150: b'\\x96',\n",
       " 151: b'\\x97',\n",
       " 152: b'\\x98',\n",
       " 153: b'\\x99',\n",
       " 154: b'\\x9a',\n",
       " 155: b'\\x9b',\n",
       " 156: b'\\x9c',\n",
       " 157: b'\\x9d',\n",
       " 158: b'\\x9e',\n",
       " 159: b'\\x9f',\n",
       " 160: b'\\xa0',\n",
       " 161: b'\\xa1',\n",
       " 162: b'\\xa2',\n",
       " 163: b'\\xa3',\n",
       " 164: b'\\xa4',\n",
       " 165: b'\\xa5',\n",
       " 166: b'\\xa6',\n",
       " 167: b'\\xa7',\n",
       " 168: b'\\xa8',\n",
       " 169: b'\\xa9',\n",
       " 170: b'\\xaa',\n",
       " 171: b'\\xab',\n",
       " 172: b'\\xac',\n",
       " 173: b'\\xad',\n",
       " 174: b'\\xae',\n",
       " 175: b'\\xaf',\n",
       " 176: b'\\xb0',\n",
       " 177: b'\\xb1',\n",
       " 178: b'\\xb2',\n",
       " 179: b'\\xb3',\n",
       " 180: b'\\xb4',\n",
       " 181: b'\\xb5',\n",
       " 182: b'\\xb6',\n",
       " 183: b'\\xb7',\n",
       " 184: b'\\xb8',\n",
       " 185: b'\\xb9',\n",
       " 186: b'\\xba',\n",
       " 187: b'\\xbb',\n",
       " 188: b'\\xbc',\n",
       " 189: b'\\xbd',\n",
       " 190: b'\\xbe',\n",
       " 191: b'\\xbf',\n",
       " 192: b'\\xc0',\n",
       " 193: b'\\xc1',\n",
       " 194: b'\\xc2',\n",
       " 195: b'\\xc3',\n",
       " 196: b'\\xc4',\n",
       " 197: b'\\xc5',\n",
       " 198: b'\\xc6',\n",
       " 199: b'\\xc7',\n",
       " 200: b'\\xc8',\n",
       " 201: b'\\xc9',\n",
       " 202: b'\\xca',\n",
       " 203: b'\\xcb',\n",
       " 204: b'\\xcc',\n",
       " 205: b'\\xcd',\n",
       " 206: b'\\xce',\n",
       " 207: b'\\xcf',\n",
       " 208: b'\\xd0',\n",
       " 209: b'\\xd1',\n",
       " 210: b'\\xd2',\n",
       " 211: b'\\xd3',\n",
       " 212: b'\\xd4',\n",
       " 213: b'\\xd5',\n",
       " 214: b'\\xd6',\n",
       " 215: b'\\xd7',\n",
       " 216: b'\\xd8',\n",
       " 217: b'\\xd9',\n",
       " 218: b'\\xda',\n",
       " 219: b'\\xdb',\n",
       " 220: b'\\xdc',\n",
       " 221: b'\\xdd',\n",
       " 222: b'\\xde',\n",
       " 223: b'\\xdf',\n",
       " 224: b'\\xe0',\n",
       " 225: b'\\xe1',\n",
       " 226: b'\\xe2',\n",
       " 227: b'\\xe3',\n",
       " 228: b'\\xe4',\n",
       " 229: b'\\xe5',\n",
       " 230: b'\\xe6',\n",
       " 231: b'\\xe7',\n",
       " 232: b'\\xe8',\n",
       " 233: b'\\xe9',\n",
       " 234: b'\\xea',\n",
       " 235: b'\\xeb',\n",
       " 236: b'\\xec',\n",
       " 237: b'\\xed',\n",
       " 238: b'\\xee',\n",
       " 239: b'\\xef',\n",
       " 240: b'\\xf0',\n",
       " 241: b'\\xf1',\n",
       " 242: b'\\xf2',\n",
       " 243: b'\\xf3',\n",
       " 244: b'\\xf4',\n",
       " 245: b'\\xf5',\n",
       " 246: b'\\xf6',\n",
       " 247: b'\\xf7',\n",
       " 248: b'\\xf8',\n",
       " 249: b'\\xf9',\n",
       " 250: b'\\xfa',\n",
       " 251: b'\\xfb',\n",
       " 252: b'\\xfc',\n",
       " 253: b'\\xfd',\n",
       " 254: b'\\xfe',\n",
       " 255: b'\\xff',\n",
       " 256: b' t',\n",
       " 257: b'he',\n",
       " 258: b' a',\n",
       " 259: b'in',\n",
       " 260: b' the',\n",
       " 261: b'er',\n",
       " 262: b'on',\n",
       " 263: b' ,',\n",
       " 264: b'ed',\n",
       " 265: b' s',\n",
       " 266: b're',\n",
       " 267: b' w',\n",
       " 268: b' o',\n",
       " 269: b'nd',\n",
       " 270: b'at',\n",
       " 271: b' .',\n",
       " 272: b'or',\n",
       " 273: b'it',\n",
       " 274: b' f',\n",
       " 275: b'is',\n",
       " 276: b'ar',\n",
       " 277: b' c',\n",
       " 278: b'en',\n",
       " 279: b'es',\n",
       " 280: b' of',\n",
       " 281: b' in',\n",
       " 282: b'an',\n",
       " 283: b'al',\n",
       " 284: b' b',\n",
       " 285: b' p',\n",
       " 286: b'ing',\n",
       " 287: b'as',\n",
       " 288: b' and',\n",
       " 289: b' to',\n",
       " 290: b'ic',\n",
       " 291: b'ro',\n",
       " 292: b' m',\n",
       " 293: b' d',\n",
       " 294: b' h',\n",
       " 295: b'ion',\n",
       " 296: b'le',\n",
       " 297: b' T',\n",
       " 298: b' re',\n",
       " 299: b'ou',\n",
       " 300: b' A',\n",
       " 301: b' =',\n",
       " 302: b' S',\n",
       " 303: b' th',\n",
       " 304: b'il',\n",
       " 305: b'ent',\n",
       " 306: b' \"',\n",
       " 307: b'ol',\n",
       " 308: b' @',\n",
       " 309: b'st',\n",
       " 310: b'el',\n",
       " 311: b' \\n',\n",
       " 312: b' \\n\\n',\n",
       " 313: b' n',\n",
       " 314: b' l',\n",
       " 315: b' C',\n",
       " 316: b'ad',\n",
       " 317: b'am',\n",
       " 318: b'om',\n",
       " 319: b'ct',\n",
       " 320: b' e',\n",
       " 321: b' was',\n",
       " 322: b' g',\n",
       " 323: b'ir',\n",
       " 324: b'ur',\n",
       " 325: b'im',\n",
       " 326: b' on',\n",
       " 327: b' for',\n",
       " 328: b' @-',\n",
       " 329: b' @-@',\n",
       " 330: b' M',\n",
       " 331: b' be',\n",
       " 332: b'ly',\n",
       " 333: b' B',\n",
       " 334: b' The',\n",
       " 335: b' I',\n",
       " 336: b'ot',\n",
       " 337: b'id',\n",
       " 338: b'ith',\n",
       " 339: b' as',\n",
       " 340: b'iv',\n",
       " 341: b'et',\n",
       " 342: b'ch',\n",
       " 343: b'ig',\n",
       " 344: b'ay',\n",
       " 345: b'ow',\n",
       " 346: b'us',\n",
       " 347: b\" '\",\n",
       " 348: b'ation',\n",
       " 349: b' with',\n",
       " 350: b'ut',\n",
       " 351: b'ce',\n",
       " 352: b' he',\n",
       " 353: b' st',\n",
       " 354: b' P',\n",
       " 355: b'ra',\n",
       " 356: b'ers',\n",
       " 357: b' that',\n",
       " 358: b' al',\n",
       " 359: b' H',\n",
       " 360: b' R',\n",
       " 361: b'um',\n",
       " 362: b' F',\n",
       " 363: b'ul',\n",
       " 364: b' W',\n",
       " 365: b'ist',\n",
       " 366: b' N',\n",
       " 367: b' G',\n",
       " 368: b' wh',\n",
       " 369: b'em',\n",
       " 370: b' an',\n",
       " 371: b'un',\n",
       " 372: b'19',\n",
       " 373: b'os',\n",
       " 374: b'ver',\n",
       " 375: b' by',\n",
       " 376: b'ter',\n",
       " 377: b' at',\n",
       " 378: b' is',\n",
       " 379: b' J',\n",
       " 380: b'th',\n",
       " 381: b' se',\n",
       " 382: b' con',\n",
       " 383: b'av',\n",
       " 384: b'rom',\n",
       " 385: b' D',\n",
       " 386: b' )',\n",
       " 387: b' (',\n",
       " 388: b'and',\n",
       " 389: b' de',\n",
       " 390: b'ag',\n",
       " 391: b' E',\n",
       " 392: b'od',\n",
       " 393: b' L',\n",
       " 394: b' his',\n",
       " 395: b'20',\n",
       " 396: b'ies',\n",
       " 397: b'ck',\n",
       " 398: b'her',\n",
       " 399: b' it',\n",
       " 400: b'pe',\n",
       " 401: b'ere',\n",
       " 402: b'ain',\n",
       " 403: b'est',\n",
       " 404: b' were',\n",
       " 405: b' pro',\n",
       " 406: b' from',\n",
       " 407: b'ri',\n",
       " 408: b'ort',\n",
       " 409: b'ord',\n",
       " 410: b'res',\n",
       " 411: b' su',\n",
       " 412: b' com',\n",
       " 413: b' v',\n",
       " 414: b' In',\n",
       " 415: b'ew',\n",
       " 416: b'if',\n",
       " 417: b' pl',\n",
       " 418: b'pp',\n",
       " 419: b' O',\n",
       " 420: b'art',\n",
       " 421: b'ill',\n",
       " 422: b'ich',\n",
       " 423: b'pt',\n",
       " 424: b' sh',\n",
       " 425: b'ate',\n",
       " 426: b'all',\n",
       " 427: b'igh',\n",
       " 428: b'ber',\n",
       " 429: b'se',\n",
       " 430: b'ld',\n",
       " 431: b' ex',\n",
       " 432: b'ated',\n",
       " 433: b' or',\n",
       " 434: b'ore',\n",
       " 435: b' \\xe2',\n",
       " 436: b'ab',\n",
       " 437: b'ame',\n",
       " 438: b'ess',\n",
       " 439: b'ak',\n",
       " 440: b'ard',\n",
       " 441: b'gh',\n",
       " 442: b'und',\n",
       " 443: b'op',\n",
       " 444: b'ong',\n",
       " 445: b'rit',\n",
       " 446: b'ru',\n",
       " 447: b' \\xe2\\x80',\n",
       " 448: b'ant',\n",
       " 449: b' K',\n",
       " 450: b' ch',\n",
       " 451: b'ity',\n",
       " 452: b' U',\n",
       " 453: b'ish',\n",
       " 454: b'og',\n",
       " 455: b'ud',\n",
       " 456: b' had',\n",
       " 457: b'qu',\n",
       " 458: b' which',\n",
       " 459: b' r',\n",
       " 460: b' le',\n",
       " 461: b'ian',\n",
       " 462: b' are',\n",
       " 463: b' ar',\n",
       " 464: b'ial',\n",
       " 465: b'ive',\n",
       " 466: b' ;',\n",
       " 467: b' St',\n",
       " 468: b'ip',\n",
       " 469: b'ear',\n",
       " 470: b'ost',\n",
       " 471: b'ia',\n",
       " 472: b'up',\n",
       " 473: b'ov',\n",
       " 474: b'so',\n",
       " 475: b'ment',\n",
       " 476: b' not',\n",
       " 477: b' Ch',\n",
       " 478: b' y',\n",
       " 479: b'our',\n",
       " 480: b'ight',\n",
       " 481: b'own',\n",
       " 482: b'ac',\n",
       " 483: b'ary',\n",
       " 484: b'200',\n",
       " 485: b'out',\n",
       " 486: b'ast',\n",
       " 487: b'ave',\n",
       " 488: b'ue',\n",
       " 489: b' \\xe2\\x80\\x93',\n",
       " 490: b'ction',\n",
       " 491: b'00',\n",
       " 492: b' k',\n",
       " 493: b'ap',\n",
       " 494: b'ide',\n",
       " 495: b'ran',\n",
       " 496: b'ell',\n",
       " 497: b'ork',\n",
       " 498: b'ine',\n",
       " 499: b'ical',\n",
       " 500: b' V',\n",
       " 501: b'cc',\n",
       " 502: b' also',\n",
       " 503: b'fter',\n",
       " 504: b'ub',\n",
       " 505: b' He',\n",
       " 506: b' their',\n",
       " 507: b' her',\n",
       " 508: b'cl',\n",
       " 509: b'ure',\n",
       " 510: b'ust',\n",
       " 511: b'ther',\n",
       " 512: b'ign',\n",
       " 513: b' rec',\n",
       " 514: b'wo',\n",
       " 515: b' fir',\n",
       " 516: b'ition',\n",
       " 517: b'oc',\n",
       " 518: b'ie',\n",
       " 519: b'ous',\n",
       " 520: b'nt',\n",
       " 521: b'ack',\n",
       " 522: b'ge',\n",
       " 523: b'ome',\n",
       " 524: b' Al',\n",
       " 525: b' te',\n",
       " 526: b' un',\n",
       " 527: b'201',\n",
       " 528: b' per',\n",
       " 529: b' cl',\n",
       " 530: b' cont',\n",
       " 531: b'man',\n",
       " 532: b'ff',\n",
       " 533: b'ime',\n",
       " 534: b' play',\n",
       " 535: b'ould',\n",
       " 536: b'hed',\n",
       " 537: b' first',\n",
       " 538: b' int',\n",
       " 539: b'ason',\n",
       " 540: b'ater',\n",
       " 541: b'oll',\n",
       " 542: b' Th',\n",
       " 543: b'ass',\n",
       " 544: b' Y',\n",
       " 545: b' sc',\n",
       " 546: b'oin',\n",
       " 547: b'pl',\n",
       " 548: b'ult',\n",
       " 549: b' one',\n",
       " 550: b'ect',\n",
       " 551: b'ire',\n",
       " 552: b' ro',\n",
       " 553: b'ond',\n",
       " 554: b'ations',\n",
       " 555: b'ey',\n",
       " 556: b'ough',\n",
       " 557: b' has',\n",
       " 558: b' ab',\n",
       " 559: b' whe',\n",
       " 560: b' its',\n",
       " 561: b' who',\n",
       " 562: b'uring',\n",
       " 563: b' two',\n",
       " 564: b' all',\n",
       " 565: b'ark',\n",
       " 566: b'ok',\n",
       " 567: b'old',\n",
       " 568: b' but',\n",
       " 569: b' @.',\n",
       " 570: b' @.@',\n",
       " 571: b'ilm',\n",
       " 572: b' this',\n",
       " 573: b'per',\n",
       " 574: b'mer',\n",
       " 575: b'ree',\n",
       " 576: b' been',\n",
       " 577: b' year',\n",
       " 578: b'ory',\n",
       " 579: b' have',\n",
       " 580: b' us',\n",
       " 581: b'du',\n",
       " 582: b' comp',\n",
       " 583: b'te',\n",
       " 584: b' j',\n",
       " 585: b'ound',\n",
       " 586: b' part',\n",
       " 587: b' ag',\n",
       " 588: b'ach',\n",
       " 589: b'port',\n",
       " 590: b' off',\n",
       " 591: b' season',\n",
       " 592: b' spe',\n",
       " 593: b' im',\n",
       " 594: b'bum',\n",
       " 595: b'18',\n",
       " 596: b'ally',\n",
       " 597: b'ence',\n",
       " 598: b' res',\n",
       " 599: b' dis',\n",
       " 600: b' god',\n",
       " 601: b'ry',\n",
       " 602: b'ile',\n",
       " 603: b'ely',\n",
       " 604: b' after',\n",
       " 605: b'ities',\n",
       " 606: b'iz',\n",
       " 607: b'ugh',\n",
       " 608: b'olog',\n",
       " 609: b' album',\n",
       " 610: b'ph',\n",
       " 611: b'are',\n",
       " 612: b' des',\n",
       " 613: b' man',\n",
       " 614: b' en',\n",
       " 615: b' she',\n",
       " 616: b' :',\n",
       " 617: b'ade',\n",
       " 618: b' @,',\n",
       " 619: b' @,@',\n",
       " 620: b' ad',\n",
       " 621: b' It',\n",
       " 622: b'ft',\n",
       " 623: b'ced',\n",
       " 624: b' time',\n",
       " 625: b' other',\n",
       " 626: b'age',\n",
       " 627: b' bec',\n",
       " 628: b'act',\n",
       " 629: b'ited',\n",
       " 630: b' go',\n",
       " 631: b'clud',\n",
       " 632: b' film',\n",
       " 633: b'ron',\n",
       " 634: b' Ar',\n",
       " 635: b'ied',\n",
       " 636: b' over',\n",
       " 637: b'ordan',\n",
       " 638: b' up',\n",
       " 639: b' Whe',\n",
       " 640: b' Jordan',\n",
       " 641: b'als',\n",
       " 642: b'ock',\n",
       " 643: b' und',\n",
       " 644: b'ib',\n",
       " 645: b'ents',\n",
       " 646: b'les',\n",
       " 647: b'ased',\n",
       " 648: b' Pol',\n",
       " 649: b'ase',\n",
       " 650: b'ric',\n",
       " 651: b'ors',\n",
       " 652: b' Sh',\n",
       " 653: b'ath',\n",
       " 654: b' Un',\n",
       " 655: b' rem',\n",
       " 656: b'for',\n",
       " 657: b' pre',\n",
       " 658: b' they',\n",
       " 659: b'ose',\n",
       " 660: b' record',\n",
       " 661: b' Re',\n",
       " 662: b' De',\n",
       " 663: b'ite',\n",
       " 664: b' air',\n",
       " 665: b'ubl',\n",
       " 666: b'ted',\n",
       " 667: b' new',\n",
       " 668: b'ance',\n",
       " 669: b' includ',\n",
       " 670: b' Se',\n",
       " 671: b' them',\n",
       " 672: b'ces',\n",
       " 673: b'199',\n",
       " 674: b' under',\n",
       " 675: b'ress',\n",
       " 676: b' out',\n",
       " 677: b' ne',\n",
       " 678: b'vi',\n",
       " 679: b'round',\n",
       " 680: b' more',\n",
       " 681: b'ned',\n",
       " 682: b'fer',\n",
       " 683: b'ts',\n",
       " 684: b'ward',\n",
       " 685: b' him',\n",
       " 686: b'ice',\n",
       " 687: b' Brit',\n",
       " 688: b'ke',\n",
       " 689: b' fin',\n",
       " 690: b'gan',\n",
       " 691: b' sec',\n",
       " 692: b'erv',\n",
       " 693: b' reg',\n",
       " 694: b'ae',\n",
       " 695: b'rough',\n",
       " 696: b'ered',\n",
       " 697: b' spec',\n",
       " 698: b' into',\n",
       " 699: b' sp',\n",
       " 700: b' team',\n",
       " 701: b'ember',\n",
       " 702: b' ev',\n",
       " 703: b' rele',\n",
       " 704: b' ear',\n",
       " 705: b'eler',\n",
       " 706: b' As',\n",
       " 707: b'ning',\n",
       " 708: b'ild',\n",
       " 709: b'reat',\n",
       " 710: b' work',\n",
       " 711: b'ace',\n",
       " 712: b'able',\n",
       " 713: b' Wheeler',\n",
       " 714: b' inter',\n",
       " 715: b' most',\n",
       " 716: b'ony',\n",
       " 717: b' co',\n",
       " 718: b'ular',\n",
       " 719: b' On',\n",
       " 720: b' tra',\n",
       " 721: b'oy',\n",
       " 722: b' ret',\n",
       " 723: b'aw',\n",
       " 724: b'oss',\n",
       " 725: b' comm',\n",
       " 726: b'rib',\n",
       " 727: b' during',\n",
       " 728: b'ens',\n",
       " 729: b' fl',\n",
       " 730: b'hip',\n",
       " 731: b' act',\n",
       " 732: b'ix',\n",
       " 733: b'chae',\n",
       " 734: b'chaeolog',\n",
       " 735: b' would',\n",
       " 736: b'oth',\n",
       " 737: b' only',\n",
       " 738: b' fe',\n",
       " 739: b'ull',\n",
       " 740: b' produ',\n",
       " 741: b'one',\n",
       " 742: b'ings',\n",
       " 743: b'ans',\n",
       " 744: b'tle',\n",
       " 745: b'red',\n",
       " 746: b' game',\n",
       " 747: b'erson',\n",
       " 748: b' Ind',\n",
       " 749: b'ee',\n",
       " 750: b' form',\n",
       " 751: b' mus',\n",
       " 752: b' four',\n",
       " 753: b'ions',\n",
       " 754: b' sub',\n",
       " 755: b'way',\n",
       " 756: b'ng',\n",
       " 757: b'ames',\n",
       " 758: b' rel',\n",
       " 759: b' cons',\n",
       " 760: b' app',\n",
       " 761: b' three',\n",
       " 762: b' publ',\n",
       " 763: b'ates',\n",
       " 764: b'land',\n",
       " 765: b'ished',\n",
       " 766: b' again',\n",
       " 767: b' att',\n",
       " 768: b' mon',\n",
       " 769: b'ind',\n",
       " 770: b' num',\n",
       " 771: b'ick',\n",
       " 772: b'row',\n",
       " 773: b'ener',\n",
       " 774: b'ail',\n",
       " 775: b'vel',\n",
       " 776: b' being',\n",
       " 777: b' kn',\n",
       " 778: b'ational',\n",
       " 779: b'ars',\n",
       " 780: b'iss',\n",
       " 781: b'ount',\n",
       " 782: b' end',\n",
       " 783: b'ject',\n",
       " 784: b' All',\n",
       " 785: b'ower',\n",
       " 786: b' second',\n",
       " 787: b'orth',\n",
       " 788: b' Town',\n",
       " 789: b'end',\n",
       " 790: b'erman',\n",
       " 791: b' British',\n",
       " 792: b' gods',\n",
       " 793: b'een',\n",
       " 794: b'ang',\n",
       " 795: b' me',\n",
       " 796: b' ant',\n",
       " 797: b'iel',\n",
       " 798: b' through',\n",
       " 799: b' German',\n",
       " 800: b'ollow',\n",
       " 801: b'arg',\n",
       " 802: b' later',\n",
       " 803: b' York',\n",
       " 804: b'cted',\n",
       " 805: b'fore',\n",
       " 806: b' bet',\n",
       " 807: b'iet',\n",
       " 808: b' min',\n",
       " 809: b' pr',\n",
       " 810: b'ake',\n",
       " 811: b' made',\n",
       " 812: b' song',\n",
       " 813: b' met',\n",
       " 814: b' acc',\n",
       " 815: b' am',\n",
       " 816: b' ap',\n",
       " 817: b'raft',\n",
       " 818: b'ook',\n",
       " 819: b' when',\n",
       " 820: b' such',\n",
       " 821: b'ict',\n",
       " 822: b'ons',\n",
       " 823: b' pol',\n",
       " 824: b' about',\n",
       " 825: b'gy',\n",
       " 826: b' some',\n",
       " 827: b' sy',\n",
       " 828: b'ins',\n",
       " 829: b' where',\n",
       " 830: b' bu',\n",
       " 831: b'air',\n",
       " 832: b'tern',\n",
       " 833: b' while',\n",
       " 834: b'ious',\n",
       " 835: b'az',\n",
       " 836: b' rep',\n",
       " 837: b' She',\n",
       " 838: b' writ',\n",
       " 839: b' so',\n",
       " 840: b' than',\n",
       " 841: b' ass',\n",
       " 842: b' inc',\n",
       " 843: b'ten',\n",
       " 844: b'outh',\n",
       " 845: b'rist',\n",
       " 846: b' New',\n",
       " 847: b' ship',\n",
       " 848: b' Polish',\n",
       " 849: b' cent',\n",
       " 850: b'000',\n",
       " 851: b'resent',\n",
       " 852: b' sur',\n",
       " 853: b'orld',\n",
       " 854: b' Le',\n",
       " 855: b' Bl',\n",
       " 856: b'ved',\n",
       " 857: b'send',\n",
       " 858: b'though',\n",
       " 859: b' lead',\n",
       " 860: b'ween',\n",
       " 861: b' sign',\n",
       " 862: b' Townsend',\n",
       " 863: b'form',\n",
       " 864: b'ised',\n",
       " 865: b'ute',\n",
       " 866: b'imony',\n",
       " 867: b'ike',\n",
       " 868: b' many',\n",
       " 869: b' ind',\n",
       " 870: b'ros',\n",
       " 871: b' char',\n",
       " 872: b'ug',\n",
       " 873: b'ague',\n",
       " 874: b'led',\n",
       " 875: b' number',\n",
       " 876: b' before',\n",
       " 877: b'veral',\n",
       " 878: b'son',\n",
       " 879: b' Egy',\n",
       " 880: b' Egypt',\n",
       " 881: b' follow',\n",
       " 882: b' supp',\n",
       " 883: b've',\n",
       " 884: b'ily',\n",
       " 885: b'elf',\n",
       " 886: b' high',\n",
       " 887: b'amp',\n",
       " 888: b' used',\n",
       " 889: b'use',\n",
       " 890: b' then',\n",
       " 891: b' appe',\n",
       " 892: b' years',\n",
       " 893: b'orn',\n",
       " 894: b'198',\n",
       " 895: b' no',\n",
       " 896: b'ual',\n",
       " 897: b' ac',\n",
       " 898: b' both',\n",
       " 899: b'ived',\n",
       " 900: b'ating',\n",
       " 901: b' do',\n",
       " 902: b'hes',\n",
       " 903: b'wn',\n",
       " 904: b' remain',\n",
       " 905: b'ern',\n",
       " 906: b'ists',\n",
       " 907: b' Christ',\n",
       " 908: b'ield',\n",
       " 909: b' between',\n",
       " 910: b'oh',\n",
       " 911: b'irect',\n",
       " 912: b'194',\n",
       " 913: b' hist',\n",
       " 914: b' inv',\n",
       " 915: b'ral',\n",
       " 916: b' archaeolog',\n",
       " 917: b'ific',\n",
       " 918: b'ale',\n",
       " 919: b'ob',\n",
       " 920: b' inst',\n",
       " 921: b' Z',\n",
       " 922: b' well',\n",
       " 923: b'rans',\n",
       " 924: b' Com',\n",
       " 925: b' these',\n",
       " 926: b'owe',\n",
       " 927: b' ele',\n",
       " 928: b' there',\n",
       " 929: b'ool',\n",
       " 930: b' began',\n",
       " 931: b' After',\n",
       " 932: b' became',\n",
       " 933: b' ob',\n",
       " 934: b' tr',\n",
       " 935: b' long',\n",
       " 936: b' At',\n",
       " 937: b'aid',\n",
       " 938: b' ra',\n",
       " 939: b'ican',\n",
       " 940: b' bel',\n",
       " 941: b'191',\n",
       " 942: b' car',\n",
       " 943: b' music',\n",
       " 944: b'pr',\n",
       " 945: b' dif',\n",
       " 946: b'emb',\n",
       " 947: b'ci',\n",
       " 948: b' dec',\n",
       " 949: b'other',\n",
       " 950: b' can',\n",
       " 951: b' war',\n",
       " 952: b' This',\n",
       " 953: b'aj',\n",
       " 954: b' pe',\n",
       " 955: b' back',\n",
       " 956: b' And',\n",
       " 957: b' disc',\n",
       " 958: b' Fey',\n",
       " 959: b' div',\n",
       " 960: b'my',\n",
       " 961: b'ty',\n",
       " 962: b'ren',\n",
       " 963: b' oper',\n",
       " 964: b' sing',\n",
       " 965: b'osed',\n",
       " 966: b' could',\n",
       " 967: b' day',\n",
       " 968: b'arch',\n",
       " 969: b' Cl',\n",
       " 970: b'oot',\n",
       " 971: b' released',\n",
       " 972: b'ah',\n",
       " 973: b' care',\n",
       " 974: b' stud',\n",
       " 975: b'ball',\n",
       " 976: b'ision',\n",
       " 977: b' mov',\n",
       " 978: b'ored',\n",
       " 979: b' known',\n",
       " 980: b' An',\n",
       " 981: b' several',\n",
       " 982: b' against',\n",
       " 983: b'ics',\n",
       " 984: b' rece',\n",
       " 985: b' imp',\n",
       " 986: b' def',\n",
       " 987: b'over',\n",
       " 988: b'ife',\n",
       " 989: b' sm',\n",
       " 990: b'ky',\n",
       " 991: b' ser',\n",
       " 992: b'ures',\n",
       " 993: b' poin',\n",
       " 994: b' dep',\n",
       " 995: b'10',\n",
       " 996: b' art',\n",
       " 997: b' qu',\n",
       " 998: b'dition',\n",
       " 999: b' appear',\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f88e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \"The goal of this test that I've mad is to see if the tokenizer works\"\n",
    "bytes = [bytes([ord(ch)]) for ch in test_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6be85c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'T',\n",
       " b'h',\n",
       " b'e',\n",
       " b' ',\n",
       " b'g',\n",
       " b'o',\n",
       " b'a',\n",
       " b'l',\n",
       " b' ',\n",
       " b'o',\n",
       " b'f',\n",
       " b' ',\n",
       " b't',\n",
       " b'h',\n",
       " b'i',\n",
       " b's',\n",
       " b' ',\n",
       " b't',\n",
       " b'e',\n",
       " b's',\n",
       " b't',\n",
       " b' ',\n",
       " b't',\n",
       " b'h',\n",
       " b'a',\n",
       " b't',\n",
       " b' ',\n",
       " b'I',\n",
       " b\"'\",\n",
       " b'v',\n",
       " b'e',\n",
       " b' ',\n",
       " b'm',\n",
       " b'a',\n",
       " b'd',\n",
       " b' ',\n",
       " b'i',\n",
       " b's',\n",
       " b' ',\n",
       " b't',\n",
       " b'o',\n",
       " b' ',\n",
       " b's',\n",
       " b'e',\n",
       " b'e',\n",
       " b' ',\n",
       " b'i',\n",
       " b'f',\n",
       " b' ',\n",
       " b't',\n",
       " b'h',\n",
       " b'e',\n",
       " b' ',\n",
       " b't',\n",
       " b'o',\n",
       " b'k',\n",
       " b'e',\n",
       " b'n',\n",
       " b'i',\n",
       " b'z',\n",
       " b'e',\n",
       " b'r',\n",
       " b' ',\n",
       " b'w',\n",
       " b'o',\n",
       " b'r',\n",
       " b'k',\n",
       " b's']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eab5fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, vocab, merges):\n",
    "    rule = re.compile(r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}++|\\p{N}{1,3}+| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*+|\\s++$|\\s*[\\r\\n]|\\s+(?!\\S)|\\s\"\"\")\n",
    "    pretokens = re.findall(rule, text)\n",
    "    merge_order = sorted(merges.items(), key=lambda x: x[1])\n",
    "    \n",
    "    token_ids = []\n",
    "    \n",
    "    for pretoken in pretokens:\n",
    "        tokens = list(pretoken.encode('utf-8'))\n",
    "        \n",
    "        for (b1, b2), merge_idx in merge_order:\n",
    "            new_tokens = []\n",
    "            i =0\n",
    "            while i < len(tokens):\n",
    "                if i < len(tokens)-1 and tokens[i] == b1 and tokens[i+1] == b2:\n",
    "                    new_tokens.append(merge_idx)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_tokens.append(tokens[i])\n",
    "                    i += 1\n",
    "            tokens = new_tokens\n",
    "            \n",
    "        token_ids.extend(tokens)\n",
    "    return token_ids\n",
    "\n",
    "test = encode(test_str, vocab, merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad36d7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'T',\n",
       " b'he',\n",
       " b' goal',\n",
       " b' of',\n",
       " b' this',\n",
       " b' test',\n",
       " b' that',\n",
       " b' I',\n",
       " b\"'\",\n",
       " b've',\n",
       " b' m',\n",
       " b'ad',\n",
       " b' is',\n",
       " b' to',\n",
       " b' see',\n",
       " b' if',\n",
       " b' the',\n",
       " b' to',\n",
       " b'ken',\n",
       " b'iz',\n",
       " b'er',\n",
       " b' works']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [vocab[token] for token in test]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe6e13df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [res.decode('utf-8') for res in result]\n",
    "val_str = ''.join(vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fd947bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The goal of this test that I've mad is to see if the tokenizer works\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f753d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
